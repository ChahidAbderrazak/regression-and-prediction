# Explainable AI (XAI)

xAI are a set of methods used to understand the factors, trends and patterns influencing the decisions made by any deep learning model. This will increase the trust of end users.

<image src="../docs/assets/xAI-recap.jpg" width=600>

## Why do we need Explainable AI (XAI)?

- **User Understanding and Trust**: encourage the adoption of AI based systems
- **Compliance and Regulations**: prove the compliance with regulations such as GDPR (General Data Protection Regulation)
- **Identify & Remove Bias**: show the influencing factors behind every prediction, helping us identify existing model biases.
- **Continuous Improvement**: such as performance degradation, data drift, etc. By understanding what goes wrong
- **Error Detection and Debugging**

## What are the Types of Explanations?

ML models can be explained at two levels: Global and Local.

- **Global Explanations**: explain the behavior of the model across the entire dataset

- **Local Explanations**: provide insights into why a particular decision was made for a specific input

# Aknowngmetn

- [Viso.ai Guide](https://viso.ai/deep-learning/explainable-ai/)
- [Pureai article](https://pureai.substack.com/p/decoding-ai-decisions-using-lime)
